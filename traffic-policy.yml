on_http_request:
  - name: Allow whitelisted IP addresses and authorized domains
    expressions:
      - |
        !(
          conn.client_ip == '44.226.145.213' ||
          conn.client_ip == '54.187.200.255' ||
          conn.client_ip == '34.213.214.55' ||
          conn.client_ip == '35.164.95.156' ||
          conn.client_ip == '44.230.95.183' ||
          conn.client_ip == '44.229.200.200' ||
          'operator.becomeomni.com' in req.headers['host'] ||
          'operator.staging.becomeomni.com' in req.headers['host'] ||
          'dev1.operator.becomeomni.com' in req.headers['host'] ||
          'localhost' in req.headers['host']
        )
    actions:
      - type: deny

  - name: Add `robots.txt` to deny all bots and crawlers
    expressions:
      - req.url.contains('/robots.txt')
    actions:
      - type: custom-response
        config:
          status_code: 200
          body: "User-agent: *\r\nDisallow: /"
          headers:
            content-type: text/plain
